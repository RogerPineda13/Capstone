{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is all over the place, don't worry will be fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import os\n",
    "from matplotlib import pyplot\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import regexp_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import wordnet\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer,\\\n",
    "HashingVectorizer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions that will be used within the notebook\n",
    "def onehotencoder(column_name, df):\n",
    "    column_name_ohe = df[[column_name]]\n",
    "    ohe = OneHotEncoder(categories = 'auto', sparse = False)\n",
    "    ohe.fit(column_name_ohe)\n",
    "    column_transformed = ohe.transform(column_name_ohe)\n",
    "    column_encoded_ohe = pd.DataFrame(column_transformed, columns = ohe.get_feature_names([column_name]), index = df.index)\n",
    "    return column_encoded_ohe\n",
    "\n",
    "def list_contains(List1, List2): \n",
    "    check = False\n",
    "  \n",
    "    # Iterate in the 1st list \n",
    "    for m in List1: \n",
    "  \n",
    "        # Iterate in the 2nd list \n",
    "        for n in List2: \n",
    "    \n",
    "            # if there is a match\n",
    "            if m == n: \n",
    "                check = True\n",
    "                return check  \n",
    "                  \n",
    "    return check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-129-cb2307ce46cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CraigslistCars.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 458\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    459\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1194\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1196\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1198\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2153\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2154\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2155\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2156\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2157\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._string_convert\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers._string_box_utf8\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df= pd.read_csv('CraigslistCars.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_1.head()\n",
    "# visually seeing the first 5 rows of the raw dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the first few lines we are seeing that there are many rows that have NaN as a value within a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Will take a random sample of a row to see if an arbritrary row will also follow suit of the first 5 rows by having \n",
    "# multiple NaN values\n",
    "df_1.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may possibly see above at least one column could have a NaN value in a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Want to see what are the 25 columns that will be dealt with. Also will see which should be the target for this dataset\n",
    "df_1.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing that within the dataset that price exists and therefore should be a solid target to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing the range of the prices\n",
    "df_1.price.min(), df_1.price.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The range of price within the dataset goes from 0 to 3,736,928,711\n",
    "# Want to check out the years of these vehicles because some older cars have been valued in the millions\n",
    "df_1.loc[df_1['price'] == df_1.price.min(), ['year']], df_1.loc[df_1['price']==df_1.price.max(), ['year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b =sns.boxplot( df_1['price'] )\n",
    "b.set(xlabel = \"Price (in $)\", title='Price Distribution')\n",
    "sns.set_style(\"dark\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing that over 30,000 rows have the price of 0 and 2 have the large value it is showing the dataset is far fromm perfect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best way to have the price of 0 not sway modeling later on is to limit price values as well as these strange values that are in the billions. Therefore will take an inner 90% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1['price'] = df_1['price'][df_1['price'].between(df_1['price'].quantile(.085), df_1['price'].quantile(.985),inclusive=True)]\n",
    "df_1.price.min(), df_1.price.max()\n",
    "# shows 100 - 59999 is an inner 90%%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Want new df with just price values that range from 100 to 59999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Making new df of just values of cars between 100 and 59,999\n",
    "df_2 = df_1.loc[(df_1['price']>100) & (df_1['price'] <59999)].copy()\n",
    "df_2.head(), len(df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with all the possible NaN values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_2.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "year, manufacturer, model, condition, cylinders, fuel, odometer, title_status, transmission, VIN, drive, size, type, paint_color\n",
    "image_url, description, county, state, lat, long, posting_date have Na values and some have around 40% of its rows with NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the 'county' column since it has the most NaN values.\n",
    "df_2['county'].value_counts()\n",
    "# is completely empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The column is not going to be useful therefore it is safe to just drop it\n",
    "df_2.drop('county', axis=1, inplace=True)\n",
    "df_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "County dealt with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'year' column is the first column that shows it has NaN values so lets take a deeper dive into the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_2['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the oldest car\n",
    "df_2['year'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking newest car\n",
    "df_2.year.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Making a sorted list of all the years of the cars represented in the dataset\n",
    "unique_years = df_2['year'].unique()\n",
    "print(sorted(unique_years))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Barring a couple of years in the early 1900's, the dataset seems to have nearly every year in the 20th century and all years that have occured in the 21st century."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_2.year.value_counts(normalize=True)\n",
    "# most of the cars stated year is within the past 6 years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=sns.boxplot(df_2.year)\n",
    "p.set(xlabel = 'Car Year ', title='Year Distribution')\n",
    "sns.set_style(\"dark\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to remove some of the lower outliers that exist in the year column so will take just price an inner 90% of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top_years = df_2.copy()\n",
    "df_top_years['year'] = df_top_years['year'][df_top_years['year'].between(df_top_years['year'].quantile(.1), df_top_years['year'].quantile(1),inclusive=True)]\n",
    "df_top_years.year.min(), df_top_years.year.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We come to see that the lower end of starting years for cars that we should be looking at is after the year 2002. Anything prior could mess up the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making new Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabbing only values with years greater than 2002\n",
    "df_limited_years= df_2.loc[df_2['year'] >2002].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_u = df_limited_years.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaleddddd = standard.fit_transform(df_u[['year']].values)\n",
    "# df_u['year']= scaleddddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = standard.inverse_transform(df_u['year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaleddddd.mean(), scaleddddd.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cc = (2022-x.mean())/ x.std()\n",
    "# cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_limited_years.year.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limited_years.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that two key columns have been dealt with it is time to start looking at the rest of the dataset and to find ways for the empty values to be filled in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A new df is being made with all the rows where the condition column does not have an NaN value.\n",
    "df_condition = df_limited_years.loc[df_limited_years['condition'].notna()].copy()\n",
    "# Taking the df above and focusing on where the 'model' column also doesn't have any NaN values.\n",
    "df_model_and_condition = df_condition.loc[df_condition['model'].notna()].copy()\n",
    "# Making an empty dictionary\n",
    "condition_dict = {}\n",
    "# This for loop will grab all the associated values of model and condition of the vehicle and save it within the dictionary \n",
    "# above\n",
    "for a, b in df_model_and_condition[['model', 'condition']].values:\n",
    "    condition_dict[a] = b\n",
    "# Here with the dictionary above it will run through the 'condition' column and fill out missing values with appropiate ones\n",
    "# found within the made dictionary above\n",
    "df_limited_years['condition'] = df_limited_years.apply(lambda x: x['condition'] if pd.isna(x['model']) or pd.notna(x['condition']) else condition_dict[x['model']] if x['model'] in condition_dict.keys() else x['condition'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We see that it filled in 116,072 NaN values within the 'condition' column\n",
    "df_limited_years.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will do same procedure as abpve with the 'cylinders' column\n",
    "df_cylinders = df_limited_years.loc[df_limited_years['cylinders'].notna()].copy()\n",
    "df_cylinders_model = df_cylinders.loc[df_cylinders['model'].notna()].copy()\n",
    "cylinders_dictionary = {}\n",
    "for c, d in df_cylinders_model[['model', 'cylinders']].values:\n",
    "    cylinders_dictionary[c] = d\n",
    "df_limited_years['cylinders'] = df_limited_years.apply( lambda x: x['cylinders'] if pd.isna( x['model'] ) or pd.notna( x['cylinders'] ) else cylinders_dictionary[x['model']] if x['model'] in cylinders_dictionary.keys() else x['cylinders'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limited_years.isna().sum()\n",
    "# 109,649 NaN values filled in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same procedure as down above\n",
    "df_manufacturer = df_limited_years.loc[df_limited_years['manufacturer'].notna()].copy()\n",
    "df_manufacturer_model = df_manufacturer.loc[df_manufacturer['model'].notna()].copy()\n",
    "manufacturer_dictionary = {}\n",
    "for e, f in df_manufacturer_model[['model', 'manufacturer']].values:\n",
    "    manufacturer_dictionary[e] = f\n",
    "df_limited_years['manufacturer'] = df_limited_years.apply( lambda x: x['manufacturer'] if pd.isna( x['model'] ) or pd.notna( x['manufacturer'] ) else manufacturer_dictionary[x['model']] if x['model'] in manufacturer_dictionary.keys() else x['manufacturer'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limited_years.isna().sum()\n",
    "# 445 NaN values filled in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A groupy forward fill can be applied here to use the model column to appropiately fill in other columns with missing values\n",
    "df_limited_years['cylinders'] = df_limited_years.groupby('model')['cylinders'].ffill()\n",
    "df_limited_years['manufacturer'] = df_limited_years.groupby('model')['manufacturer'].ffill()\n",
    "df_limited_years['fuel']=df_limited_years.groupby('model')['fuel'].ffill()\n",
    "df_limited_years['odometer'] = df_limited_years['odometer'].fillna(df_limited_years.groupby(['year','model'])['odometer'].transform('mean'))\n",
    "df_limited_years['size']= df_limited_years.groupby('model')['size'].ffill()\n",
    "df_limited_years['type']= df_limited_years.groupby('model')['type'].ffill()\n",
    "df_limited_years['manufacturer']= df_limited_years.groupby('model')['manufacturer'].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_limited_years.isna().sum()\n",
    "# cylinders filled in 1,410 NaN values\n",
    "# condition filled in none\n",
    "# fuel filled in 816 NaN values\n",
    "# odometer with transforming and using the mean filled in 1658\n",
    "# size filled in 162,271 NaN values\n",
    "# type filled in 59,738 NaN values\n",
    "# manufacturer filled in none "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manufacturer is a very important column so want to see what car makers are in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_manufacturer = df_2['manufacturer'].unique()\n",
    "manufacturer_list = list(unique_manufacturer)\n",
    "manufacturer_list =manufacturer_list[1:]\n",
    "manufacturer_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing there are a variety of car makers from around the world exists in the dataset then it is key to find ways to fill in the column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Through domain knowledge the description of the vehicle is bound to have the name of the car maker within it. Below I will check to see if that is the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking in a sample of a description of a row whose manufacturer value is NaN to see if the value is is in the description \n",
    "# column.\n",
    "sample = df_2['description'][97]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(sample)\n",
    "# Checking the length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing that it is 4573 in length and it contains punction will use regexptokenizer to remove punctions and simply the \n",
    "# sample\n",
    "pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "tokenizer = RegexpTokenizer(pattern)\n",
    "sample_doc = tokenizer.tokenize(sample)\n",
    "sample_doc = [token.lower() for token in sample_doc]\n",
    "sw =stopwords.words('english')\n",
    "sample_doc = [token for token in sample_doc if token not in sw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(sample_doc))\n",
    "# The length of the sample has decresed to 252 in length making it easier on the machine to run through and search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sample_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using the function list_contains to see if it true whether the sample doc has at least one of the strings in the\n",
    "# manufacturer list\n",
    "List1 = unique_manufacturer\n",
    "List2 = sample_doc \n",
    "print(\"Test Case#1 \", list_contains(List1, List2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comes out to be that the description does have a car makers name within it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seeing which car maker is within the desciption\n",
    "car = set(unique_manufacturer) & set(sample_doc)\n",
    "car"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With it proven that the car makers name can be found with the description of the vehicle will now use the description column to help fill out the NaN values within the manufacturer column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Making a new df where it is grabbing all the rows where the manufacturer is NaN and grabbing its associated description\n",
    "# and id column\n",
    "manu_desc=df_limited_years.loc[df_limited_years['manufacturer'].isna(), ['description','manufacturer', 'id']].copy()\n",
    "manu_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercasing and making strings to all the values within the description column since the list of manufacturer are all\n",
    "# lowercase\n",
    "manu_desc['description']=manu_desc['description'].str.lower().str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checking to see if it worked\n",
    "manu_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Now making for loops to run through and fill in an empty list with the common values\n",
    "index_nums=[]\n",
    "m =[]\n",
    "for index, row in manu_desc.iterrows():   #runs through all the rows grabbing the index and the complete value\n",
    "    for manufacturer in manufacturer_list: #runs through the manufacturer list \n",
    "        if manufacturer in row['description']:  #seeing if the value has a common value from the list\n",
    "            index_nums.append(index)        #appending its index to index_nums empty list from above\n",
    "            m.append(manufacturer)          #appending the assocaited values from the list and row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here was just showing the result of the loop showing that it work. But it is very long and takes up a lot of space on the\n",
    "# repo so it is commented out. For those cloning it down you can uncomment it and look\n",
    "# result = [None]*(len(index_nums)+len(m))\n",
    "# result[::2] = index_nums\n",
    "# result[1::2] =m\n",
    "\n",
    "# for x, y in zip(result[::2], result[1::2]):\n",
    "    \n",
    "#     print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a new df from the values grabbed from the for loop above to now associate the row with the new value\n",
    "manu_desc_completed = pd.DataFrame(index_nums, columns=['index'])    \n",
    "manu_desc_completed['manufacturer'] = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "manu_desc_completed.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "manu_desc_completed_new=manu_desc_completed.drop_duplicates(subset=['index']) #just grabbing first appearance of whatever\n",
    "# value came from the for loop since cars can have more than one maker\n",
    "manu_desc_completed_new.manufacturer.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manu_desc_completed_new.set_index('index',inplace=True ) reseting the index to the index column made above\n",
    "manu_desc_completed_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yo= df_limited_years.copy() #making a new df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_yo.update(manu_desc_completed_new)  #Using the the update method to fill in the missing values that were generated from\n",
    "# operations above\n",
    "df_yo.isna().sum()\n",
    "# We see 2,716 NaN values were filled in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing that the description column could fill in NaN values for the manufacturer it probably can work for other columns as well. The same steps from the procedure above will be used on other columns that are deemed fit to have this work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a list of the condition of the vehicle\n",
    "unique_condition = df_2['condition'].unique()\n",
    "condition_list = list(unique_condition)\n",
    "condition_list =condition_list[1:]\n",
    "condition_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New df with all rows of NaN values from condition\n",
    "cond_desc=df_limited_years.loc[df_limited_years['condition'].isna(), ['description','condition', 'id']].copy()\n",
    "cond_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_desc['description']=cond_desc['description'].str.lower().str.split()\n",
    "# lowering the description column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing index and value of occurance\n",
    "index_nums2=[]\n",
    "c =[]\n",
    "for index, row in cond_desc.iterrows():\n",
    "    for condition in condition_list:\n",
    "        if condition in row['description']:\n",
    "            index_nums2.append(index)\n",
    "            c.append(condition)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as above with printed out version of it working\n",
    "# result2 = [None]*(len(index_nums2)+len(c))\n",
    "# result2[::2] = index_nums2\n",
    "# result2[1::2] =c\n",
    "\n",
    "# for x, y in zip(result2[::2], result2[1::2]):\n",
    "    \n",
    "#     print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_desc_completed = pd.DataFrame(index_nums2, columns=['index'])\n",
    "cond_desc_completed['condition'] = c\n",
    "cond_desc_completed_new=cond_desc_completed.drop_duplicates(subset=['index'])\n",
    "cond_desc_completed_new.set_index('index',inplace=True )\n",
    "cond_desc_completed_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yo.update(cond_desc_completed_new)\n",
    "df_yo.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_cylinders = df_2['cylinders'].unique()\n",
    "# cylinders_list = list(unique_cylinders)\n",
    "# cylinders_list = cylinders_list[1:]\n",
    "# cylinders_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# cyld_desc=df_limited_years.loc[df_limited_years['cylinders'].isna(), ['description','cylinders', 'id']].copy()\n",
    "# cyld_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cyld_desc['description']=cyld_desc['description'].str.lower().str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ll=[]\n",
    "# cy =[]\n",
    "# for index, row in cyld_desc.iterrows():\n",
    "#     for cylinders in cylinders_list:\n",
    "#         if cylinders in row['description']:\n",
    "#             ll.append(index)\n",
    "#             cy.append(manufacturer)  \n",
    "# result3 = [None]*(len(ll)+len(cy))\n",
    "# result3[::2] = ll\n",
    "# result3[1::2] =cy\n",
    "# result3\n",
    "# # for x, y in zip(result3[::2], result3[1::2]):\n",
    "    \n",
    "# #     print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_fuel = df_limited_years['fuel'].unique()\n",
    "fuel_list = list(unique_fuel)\n",
    "fuel_list = ['gas', 'diesel', 'hybrid', 'electric']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_desc=df_limited_years.loc[df_limited_years['fuel'].isna(), ['description','fuel', 'id']].copy()\n",
    "fuel_desc['description']=fuel_desc['description'].str.lower().str.split()\n",
    "fuel_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_nums4=[]\n",
    "f =[]\n",
    "for index, row in fuel_desc.iterrows():\n",
    "    for fuel in fuel_list:\n",
    "        if fuel in row['description']:\n",
    "            index_nums4.append(index)\n",
    "            f.append(fuel)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result4 = [None]*(len(index_nums4)+len(f))\n",
    "# result4[::2] = index_nums4\n",
    "# result4[1::2] =f\n",
    "\n",
    "# for x, y in zip(result4[::2], result4[1::2]):\n",
    "    \n",
    "#     print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuel_desc_completed = pd.DataFrame(index_nums4, columns=['index'])\n",
    "fuel_desc_completed['fuel'] = f\n",
    "fuel_desc_completed_new=fuel_desc_completed.drop_duplicates(subset=['index'])\n",
    "fuel_desc_completed_new.set_index('index',inplace=True )\n",
    "fuel_desc_completed_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yo.update(fuel_desc_completed_new)\n",
    "df_yo.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_transmission = df_limited_years['transmission'].unique()\n",
    "trasnmission_list = list(unique_transmission)\n",
    "transmission_list = ['automatic', 'manual']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_desc=df_limited_years.loc[df_limited_years['transmission'].isna(), ['description','transmission', 'id']].copy()\n",
    "tran_desc['description']=tran_desc['description'].str.lower().str.split()\n",
    "tran_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_nums5=[]\n",
    "t =[]\n",
    "for index, row in tran_desc.iterrows():\n",
    "    for transmission in transmission_list:\n",
    "        if transmission in row['description']:\n",
    "            index_nums5.append(index)\n",
    "            t.append(transmission)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result5 = [None]*(len(index_nums5)+len(t))\n",
    "# result5[::2] = index_nums5\n",
    "# result5[1::2] =t\n",
    "\n",
    "# for x, y in zip(result5[::2], result5[1::2]):\n",
    "    \n",
    "#     print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tran_desc_completed = pd.DataFrame(index_nums5, columns=['index'])\n",
    "tran_desc_completed['transmission'] = t\n",
    "tran_desc_completed_new=tran_desc_completed.drop_duplicates(subset=['index'])\n",
    "tran_desc_completed_new.set_index('index',inplace=True )\n",
    "tran_desc_completed_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yo.update(tran_desc_completed_new)\n",
    "df_yo.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_drive = df_limited_years['drive'].unique()\n",
    "drive_list = list(unique_drive)\n",
    "drive_list= drive_list[1:]\n",
    "drive_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "driv_desc=df_limited_years.loc[df_limited_years['drive'].isna(), ['description','drive', 'id']].copy()\n",
    "driv_desc['description']=driv_desc['description'].str.lower().str.split()\n",
    "driv_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driv_desc.isna().sum()\n",
    "# Seeing if any NaN values exist within the description column because it will interfere with the for loop\n",
    "# There is and that row will be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "driv_desc.dropna(subset=['description'], axis=0, inplace=True)\n",
    "# dropping the row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_nums6=[]\n",
    "d =[]\n",
    "for index, row in driv_desc.iterrows():\n",
    "    for drive in drive_list:\n",
    "        if drive in row['description']:\n",
    "            index_nums6.append(index)\n",
    "            d.append(drive)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result6 = [None]*(len(index_nums6)+len(d))\n",
    "# result6[::2] = index_nums6\n",
    "# result6[1::2] =d\n",
    "\n",
    "# for x, y in zip(result6[::2], result6[1::2]):\n",
    "    \n",
    "#     print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driv_desc_completed = pd.DataFrame(index_nums6, columns=['index'])\n",
    "driv_desc_completed['drive'] = d\n",
    "driv_desc_completed_new=driv_desc_completed.drop_duplicates(subset=['index'])\n",
    "driv_desc_completed_new.set_index('index',inplace=True )\n",
    "driv_desc_completed_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yo.update(driv_desc_completed_new)\n",
    "df_yo.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_size = df_limited_years['size'].unique()\n",
    "size_list = list(unique_size)\n",
    "size_list= size_list[1:]\n",
    "size_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_desc=df_limited_years.loc[df_limited_years['size'].isna(), ['description','size', 'id']].copy()\n",
    "size_desc['description']=size_desc['description'].str.lower().str.split()\n",
    "size_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_nums7=[]\n",
    "s =[]\n",
    "for index, row in size_desc.iterrows():\n",
    "    for size in size_list:\n",
    "        if size in row['description']:\n",
    "            index_nums7.append(index)\n",
    "            s.append(size)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result7 = [None]*(len(index_nums7)+len(s))\n",
    "# result7[::2] = index_nums7\n",
    "# result7[1::2] =s\n",
    "\n",
    "# for x, y in zip(result7[::2], result7[1::2]):\n",
    "    \n",
    "#     print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_desc_completed = pd.DataFrame(index_nums7, columns=['index'])\n",
    "size_desc_completed['size'] = s\n",
    "size_desc_completed_new=size_desc_completed.drop_duplicates(subset=['index'])\n",
    "size_desc_completed_new.set_index('index',inplace=True )\n",
    "size_desc_completed_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_yo.update(size_desc_completed_new)\n",
    "df_yo.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_yo['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_type = df_limited_years['type'].unique()\n",
    "type_list = list(unique_type)\n",
    "# type_list= type_list[1:]\n",
    "type_list = ['pickup',\n",
    " 'truck',\n",
    " 'other',\n",
    " 'coupe',\n",
    " 'SUV',\n",
    " 'hatchback',\n",
    " 'mini-van',\n",
    " 'sedan',\n",
    " 'offroad',\n",
    " 'bus',\n",
    " 'convertible',\n",
    " 'wagon',\n",
    " 'van']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_desc=df_limited_years.loc[df_limited_years['type'].isna(), ['description','type', 'id']].copy()\n",
    "type_desc['description']=type_desc['description'].str.lower().str.split()\n",
    "type_desc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_nums8=[]\n",
    "ty =[]\n",
    "for index, row in type_desc.iterrows():\n",
    "    for types in type_list:\n",
    "        if types in row['description']:\n",
    "            index_nums8.append(index)\n",
    "            ty.append(types)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result8 = [None]*(len(index_nums8)+len(ty))\n",
    "# result8[::2] = index_nums8\n",
    "# result8[1::2] =ty\n",
    "\n",
    "# for x, y in zip(result8[::2], result8[1::2]):\n",
    "    \n",
    "#     print(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type_desc_completed = pd.DataFrame(index_nums8, columns=['index'])\n",
    "type_desc_completed['type'] = ty\n",
    "type_desc_completed_new=type_desc_completed.drop_duplicates(subset=['index'])\n",
    "type_desc_completed_new.set_index('index',inplace=True )\n",
    "type_desc_completed_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_yo.update(type_desc_completed_new)\n",
    "df_yo.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_yo.drop(['id', 'url', 'region_url', 'VIN', 'image_url', 'description', 'lat', 'long', 'posting_date'], axis=1, inplace=True)\n",
    "df_yo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 151003 entries, 31 to 426872\n",
      "Data columns (total 16 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   region        151003 non-null  object \n",
      " 1   price         151003 non-null  float64\n",
      " 2   year          151003 non-null  float64\n",
      " 3   manufacturer  151003 non-null  object \n",
      " 4   model         151003 non-null  object \n",
      " 5   condition     151003 non-null  object \n",
      " 6   cylinders     151003 non-null  object \n",
      " 7   fuel          151003 non-null  object \n",
      " 8   odometer      151003 non-null  float64\n",
      " 9   title_status  151003 non-null  object \n",
      " 10  transmission  151003 non-null  object \n",
      " 11  drive         151003 non-null  object \n",
      " 12  size          151003 non-null  object \n",
      " 13  type          151003 non-null  object \n",
      " 14  paint_color   151003 non-null  object \n",
      " 15  state         151003 non-null  object \n",
      "dtypes: float64(3), object(13)\n",
      "memory usage: 19.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_yo1 = df_yo.copy()\n",
    "df_yo1.dropna(inplace=True)\n",
    "df_yo1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yo2=df_yo.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 290827 entries, 27 to 426878\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   region        290827 non-null  object \n",
      " 1   price         290827 non-null  float64\n",
      " 2   year          290827 non-null  float64\n",
      " 3   manufacturer  290827 non-null  object \n",
      " 4   model         290827 non-null  object \n",
      " 5   condition     290827 non-null  object \n",
      " 6   cylinders     290827 non-null  object \n",
      " 7   fuel          290827 non-null  object \n",
      " 8   odometer      290827 non-null  float64\n",
      " 9   title_status  290827 non-null  object \n",
      " 10  transmission  290827 non-null  object \n",
      " 11  type          290827 non-null  object \n",
      " 12  state         290827 non-null  object \n",
      "dtypes: float64(3), object(10)\n",
      "memory usage: 31.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_yo2.drop(['drive', 'size', 'paint_color'], axis=1,inplace=True)\n",
    "df_yo2.dropna(inplace=True)\n",
    "df_yo2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>condition</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>fuel</th>\n",
       "      <th>odometer</th>\n",
       "      <th>title_status</th>\n",
       "      <th>transmission</th>\n",
       "      <th>type</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>auburn</td>\n",
       "      <td>33590.0</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>gmc</td>\n",
       "      <td>sierra 1500 crew cab slt</td>\n",
       "      <td>good</td>\n",
       "      <td>8 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>57923.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>other</td>\n",
       "      <td>pickup</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>auburn</td>\n",
       "      <td>22590.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>chevrolet</td>\n",
       "      <td>silverado 1500</td>\n",
       "      <td>good</td>\n",
       "      <td>8 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>71229.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>other</td>\n",
       "      <td>pickup</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>auburn</td>\n",
       "      <td>39590.0</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>gmc</td>\n",
       "      <td>silverado 1500 crew</td>\n",
       "      <td>good</td>\n",
       "      <td>8 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>19160.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>other</td>\n",
       "      <td>pickup</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>auburn</td>\n",
       "      <td>30990.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>toyota</td>\n",
       "      <td>tundra double cab sr</td>\n",
       "      <td>good</td>\n",
       "      <td>8 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>41124.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>other</td>\n",
       "      <td>pickup</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>auburn</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>ford</td>\n",
       "      <td>f-150 xlt</td>\n",
       "      <td>excellent</td>\n",
       "      <td>6 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>truck</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    region    price    year manufacturer                     model  condition  \\\n",
       "27  auburn  33590.0  2014.0          gmc  sierra 1500 crew cab slt       good   \n",
       "28  auburn  22590.0  2010.0    chevrolet            silverado 1500       good   \n",
       "29  auburn  39590.0  2020.0          gmc       silverado 1500 crew       good   \n",
       "30  auburn  30990.0  2017.0       toyota      tundra double cab sr       good   \n",
       "31  auburn  15000.0  2013.0         ford                 f-150 xlt  excellent   \n",
       "\n",
       "      cylinders fuel  odometer title_status transmission    type state  \n",
       "27  8 cylinders  gas   57923.0        clean        other  pickup    al  \n",
       "28  8 cylinders  gas   71229.0        clean        other  pickup    al  \n",
       "29  8 cylinders  gas   19160.0        clean        other  pickup    al  \n",
       "30  8 cylinders  gas   41124.0        clean        other  pickup    al  \n",
       "31  6 cylinders  gas  128000.0        clean    automatic   truck    al  "
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yo2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "white     37467\n",
       "black     30766\n",
       "silver    23450\n",
       "grey      16762\n",
       "blue      15528\n",
       "red       14472\n",
       "custom     4234\n",
       "brown      3371\n",
       "green      2951\n",
       "orange      834\n",
       "yellow      806\n",
       "purple      362\n",
       "Name: paint_color, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yo1['paint_color'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>region</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>model</th>\n",
       "      <th>condition</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>fuel</th>\n",
       "      <th>odometer</th>\n",
       "      <th>title_status</th>\n",
       "      <th>transmission</th>\n",
       "      <th>drive</th>\n",
       "      <th>size</th>\n",
       "      <th>type</th>\n",
       "      <th>paint_color</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>auburn</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>ford</td>\n",
       "      <td>f-150 xlt</td>\n",
       "      <td>excellent</td>\n",
       "      <td>6 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>128000.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>rwd</td>\n",
       "      <td>full-size</td>\n",
       "      <td>truck</td>\n",
       "      <td>black</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>auburn</td>\n",
       "      <td>19900.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>ford</td>\n",
       "      <td>f250 super duty</td>\n",
       "      <td>good</td>\n",
       "      <td>8 cylinders</td>\n",
       "      <td>diesel</td>\n",
       "      <td>88000.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>4wd</td>\n",
       "      <td>full-size</td>\n",
       "      <td>pickup</td>\n",
       "      <td>blue</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>auburn</td>\n",
       "      <td>14000.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>gmc</td>\n",
       "      <td>odyssey</td>\n",
       "      <td>excellent</td>\n",
       "      <td>6 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>95000.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>fwd</td>\n",
       "      <td>full-size</td>\n",
       "      <td>mini-van</td>\n",
       "      <td>silver</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>auburn</td>\n",
       "      <td>15000.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>dodge</td>\n",
       "      <td>charger rt 4dr sedan</td>\n",
       "      <td>excellent</td>\n",
       "      <td>8 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>rebuilt</td>\n",
       "      <td>automatic</td>\n",
       "      <td>rwd</td>\n",
       "      <td>mid-size</td>\n",
       "      <td>sedan</td>\n",
       "      <td>grey</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>auburn</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>chrysler</td>\n",
       "      <td>town &amp; country</td>\n",
       "      <td>good</td>\n",
       "      <td>6 cylinders</td>\n",
       "      <td>gas</td>\n",
       "      <td>176144.0</td>\n",
       "      <td>clean</td>\n",
       "      <td>automatic</td>\n",
       "      <td>fwd</td>\n",
       "      <td>mid-size</td>\n",
       "      <td>mini-van</td>\n",
       "      <td>silver</td>\n",
       "      <td>al</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    region    price    year manufacturer                 model  condition  \\\n",
       "31  auburn  15000.0  2013.0         ford             f-150 xlt  excellent   \n",
       "55  auburn  19900.0  2004.0         ford       f250 super duty       good   \n",
       "59  auburn  14000.0  2012.0          gmc               odyssey  excellent   \n",
       "73  auburn  15000.0  2017.0        dodge  charger rt 4dr sedan  excellent   \n",
       "86  auburn   3000.0  2004.0     chrysler        town & country       good   \n",
       "\n",
       "      cylinders    fuel  odometer title_status transmission drive       size  \\\n",
       "31  6 cylinders     gas  128000.0        clean    automatic   rwd  full-size   \n",
       "55  8 cylinders  diesel   88000.0        clean    automatic   4wd  full-size   \n",
       "59  6 cylinders     gas   95000.0        clean    automatic   fwd  full-size   \n",
       "73  8 cylinders     gas   90000.0      rebuilt    automatic   rwd   mid-size   \n",
       "86  6 cylinders     gas  176144.0        clean    automatic   fwd   mid-size   \n",
       "\n",
       "        type paint_color state  \n",
       "31     truck       black    al  \n",
       "55    pickup        blue    al  \n",
       "59  mini-van      silver    al  \n",
       "73     sedan        grey    al  \n",
       "86  mini-van      silver    al  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yo1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yo1 = df_yo1.loc[df_yo1['odometer'] < 500000]\n",
    "df_yo1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = onehotencoder('region' , df_yo1)\n",
    "b = onehotencoder('manufacturer' , df_yo1)\n",
    "# c = onehotencoder('model' , df_3)    too messy of a clumn therefore will be left out\n",
    "d = onehotencoder('condition' , df_yo1)\n",
    "e = onehotencoder('cylinders' , df_yo1)\n",
    "f = onehotencoder('fuel' , df_yo1)\n",
    "g = onehotencoder('title_status' , df_yo1)\n",
    "h = onehotencoder('transmission' , df_yo1)\n",
    "i = onehotencoder('drive' , df_yo1)\n",
    "j = onehotencoder('size' , df_yo1)\n",
    "k = onehotencoder('type', df_yo1)\n",
    "l = onehotencoder('paint_color' , df_yo1)\n",
    "m = onehotencoder('state', df_yo1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "region          0\n",
       "price           0\n",
       "year            0\n",
       "manufacturer    0\n",
       "model           0\n",
       "condition       0\n",
       "cylinders       0\n",
       "fuel            0\n",
       "odometer        0\n",
       "title_status    0\n",
       "transmission    0\n",
       "drive           0\n",
       "size            0\n",
       "type            0\n",
       "paint_color     0\n",
       "state           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yo1.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.1400507021695945, 2012.417203631716, 4.477836136577988)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e3 =(2022-df_yo1['year'].mean())/df_yo1['year'].std()\n",
    "e3,df_yo1['year'].mean(),df_yo1['year'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102836.53701866485, 57728.5872305997, 499232.0)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_yo1['odometer'].mean(), df_yo1['odometer'].std(), df_yo1['odometer'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 150864 entries, 31 to 426872\n",
      "Data columns (total 16 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   region        150864 non-null  object \n",
      " 1   price         150864 non-null  float64\n",
      " 2   year          150864 non-null  float64\n",
      " 3   manufacturer  150864 non-null  object \n",
      " 4   model         150864 non-null  object \n",
      " 5   condition     150864 non-null  object \n",
      " 6   cylinders     150864 non-null  object \n",
      " 7   fuel          150864 non-null  object \n",
      " 8   odometer      150864 non-null  float64\n",
      " 9   title_status  150864 non-null  object \n",
      " 10  transmission  150864 non-null  object \n",
      " 11  drive         150864 non-null  object \n",
      " 12  size          150864 non-null  object \n",
      " 13  type          150864 non-null  object \n",
      " 14  paint_color   150864 non-null  object \n",
      " 15  state         150864 non-null  object \n",
      "dtypes: float64(3), object(13)\n",
      "memory usage: 19.6+ MB\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final1 = pd.concat([df_yo1,b,d,e,f,g,h,i,j,k,l,m], axis=1)\n",
    "df_final1.drop(['drive','region', 'manufacturer', 'condition', 'cylinders', 'fuel', 'title_status', 'transmission', 'size', 'type', 'state', 'paint_color'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_ss = ['year']\n",
    "ss = StandardScaler()\n",
    "Scaled = ss.fit_transform(df_final1[col_ss])\n",
    "Scaled = pd.DataFrame(Scaled, index=df_final1.index)\n",
    "Scaled.columns = col_ss\n",
    "df_final1['year'] = Scaled['year']\n",
    "\n",
    "\n",
    "col_sss = ['odometer']\n",
    "Scaledd = ss.fit_transform(df_final1[col_sss])\n",
    "Scaledd = pd.DataFrame(Scaledd, index=df_final1.index)\n",
    "Scaledd.columns = col_sss\n",
    "df_final1['odometer'] = Scaledd['odometer']\n",
    "\n",
    "df_final1['price'] = np.log(df_final1['price'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cars.pkl', 'wb') as carpickle:\n",
    "    pickle.dump(df_final1,carpickle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 150864 entries, 31 to 426872\n",
      "Columns: 156 entries, price to state_wy\n",
      "dtypes: float64(155), object(1)\n",
      "memory usage: 185.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_final1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = onehotencoder('region' , df_yo2)\n",
    "# b = onehotencoder('manufacturer' , df_yo2)\n",
    "# # c = onehotencoder('model' , df_3) too messy of a column\n",
    "# d = onehotencoder('condition' , df_yo2)\n",
    "# e = onehotencoder('cylinders' , df_yo2)\n",
    "# f = onehotencoder('fuel' , df_yo2)\n",
    "# g = onehotencoder('title_status' , df_yo2)\n",
    "# h = onehotencoder('transmission' , df_yo2)\n",
    "# i = onehotencoder('type', df_yo2)\n",
    "# j = onehotencoder('state', df_yo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_yo3 =df_yo2.copy()\n",
    "# df_yo3.drop(['region', 'manufacturer', 'condition', 'cylinders', 'fuel', 'title_status', 'transmission','type', 'state'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_yo4 = pd.concat([a,b,d,e,f,g,h,i,j], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_yo5 = pd.concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final2 = pd.concat([df_yo3,a,b,d,e,f,g,h,i,j], axis=1)\n",
    "# df_final2.drop(['region', 'manufacturer', 'condition', 'cylinders', 'fuel', 'title_status', 'transmission','type', 'state'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_final2['price'] = np.log(df_final2['price'])\n",
    "\n",
    "# scaledddddd = ss.fit_transform(df_final2[['odometer']].values)\n",
    "# df_final2['odometer']= scaledddddd\n",
    "\n",
    "# scaleddddd = ss.fit_transform(df_final2[['year']].values)\n",
    "# df_final2['year']= scaleddddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('cars_witthout_drive_size_paint_NaN.pkl', 'wb') as carpickles:\n",
    "#     pickle.dump(df_final2,carpickles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
